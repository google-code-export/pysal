***************
Spatial Weights
***************

Introduction
============

Spatial weights are central components of many areas of spatial analysis. In
general terms, for a spatial data set composed of n locations (points, areal
units, network edges, etc), the spatial weights matrix expresses the potential
for interaction between observations at each pair i,j of locations. There is a rich
variety of ways to specify the structure of these weights, and
PySAL supports the creation, manipulation and analysis of spatial weights
matrices across three different general types:

 * Contiguity Based Weights
 * Distance Based Weights
 * Kernel Weights

These different types of weights are implemented as instances of the PySAL weights class 
:class:`~pysal.weights.W`. 

In what follows, we provide a high level overview of spatial weights in PySAL, starting with the three different types of weights, followed by
a closer look at the properties of the W class and some related functions.[#]_

PySAL Spatial Weight Types
==========================

Contiguity Based Weights
------------------------

To illustrate the general weights object, we start with a simple contiguity
matrix constructed for a 5 by 5 lattice (composed of 25 spatial units)::

    >>> import pysal
    >>>
    >>> w=pysal.lat2W(5,5)

The w object has a number of attributes::

    >>> w.n
    25
    >>> w.pct_nonzero
    0.128
    >>> w.weights[0]
    [1.0, 1.0]
    >>> w.neighbors[0]
    [5, 1]
    >>> w.neighbors[5]
    [0, 10, 6]
    >>> w.histogram
    [(2, 4), (3, 12), (4, 9)]

n is the number of spatial units, so conceptually we could be thinking that the
weights are stored in a 25x25 matrix. However, as the second attribute
(pct_nonzero) indicates, many of the elements of this matrix would be 0 in
value so such a representation would not be efficient. Instead, the key
attributes used to store contiguity relations in W are the neighbors and
weights attributes. Both are special cases [#]_ of Python dictionaries where the key
is the id for a spatial unit and the value is a Python list of neighbor ids or
weight values. In the example above we see that the observation
with id 0 (Python is zero-offset) has two neighbors with ids [5, 1] each of
which have equal weights of 1.0.

The histogram attribute is a set of tuples indicating the cardinality of the
neighbor relations. In this case we have a regular lattice, so there are 4 units that have 2
neighbors (corner cells), 12 units with 3 neighbors (edge cells), and 9 units
with 4 neighbors (internal cells).

In the above example, the default criterion for contiguity on the lattice was
that of the rook which takes as neighbors any pair of cells that share an edge.
Alternatively, we could have used the queen criterion to include the vertices
of the lattice to define contiguities:

	>>> wq=pysal.lat2W(rook=False)
	>>> wq.neighbors[0]
	[5, 1, 6]
	>>> 

.. (Illustrate bishop using functionality in WSets)


The lat2W function is particularly useful in setting up simulation experiments
requiring a regular grid. For empirical research, a common use case is to have
a shapefile, which is a nontopological vector data structure, and a need
to carry out some form of spatial analysis that requires spatial weights. Since
topology is not stored in the underlying file there is a need to construct
the spatial weights prior to carrying out the analysis. In PySAL spatial
weights can be obtained directly from shapefiles:

    >>> w=pysal.rook_from_shapefile("examples/columbus.shp")
    >>> w.n
    49
    >>> w.pct_nonzero
    0.083298625572678045
    >>> w.histogram
    [(2, 7), (3, 10), (4, 17), (5, 8), (6, 3), (7, 3), (8, 0), (9, 1)]

If queen, rather than rook, contiguity is required then the following would work:

    >>> w=pysal.queen_from_shapefile("examples/columbus.shp")
    >>> w.pct_nonzero
    0.098292378175760101
    >>> w.histogram
    [(2, 5), (3, 9), (4, 12), (5, 5), (6, 9), (7, 3), (8, 4), (9, 1), (10, 1)]
    


Distance Based Weights
----------------------

In addition to using contiguity to define  neighbor relations, more general
functions of the distance separating observations can be used to specify the
weights.

k-nearest neighbor weights
--------------------------

The neighbors for a given observations can be defined using a k-nearest neighbor criterion.
For example we could use the the centroids of our
5x5 lattice as point locations to measure the distances:

	>>> import numpy as np
	>>> data=np.array([ord.flatten() for ord in np.indices((5,5))]).transpose()

then define the knn set as:

	>>> wknn3=pysal.knnW(data,k=3)
	>>> wknn3.neighbors[0]
	[1, 5, 6]
	>>> wknn3.s0
	75
	>>> w4=pysal.knnW(data,k=4)
	>>> w4.neighbors[0]
	[1, 5, 6, 2]
	>>> w4.s0
	100
	>>> w4.weights[0]
	[1, 1, 1, 1]


Distance band weights
---------------------

Knn weights ensure that all observations have the same number of neighbors.  [#]_
An alternative distance based set of weights relies on distance bands or
thresholds to define the neighbor set for each spatial unit as those other units
falling within a threshold distance of the focal unit:

	>>> wthresh=pysal.threshold_binaryW_from_array(data,2)
	>>> wthresh.neighbors[0]
	[1, 2, 5, 6, 10]
	>>> wthresh.neighbors[1]
	[0, 2, 5, 6, 7, 11, 3]
	>>> wthresh.weights[0]
	[1, 1, 1, 1, 1]
	>>> wthresh.weights[1]
	[1, 1, 1, 1, 1, 1, 1]
	>>> 

As can be seen in the above example, the number of neighbors is likely to vary
across observations with distance band weights in contrast to what holds for
knn weights.

Distance band weights can be generated for shapefiles as well as arrays of points. First, the 
minimum nearest neighbor distance should be determined so that each unit is assured of at least one 
neighbor:

    >>> thresh=pysal.min_threshold_dist_from_shapefile("examples/columbus.shp")
    >>> thresh
    0.61886415807685413

with this threshold in hand, the distance band weights are obtained as:

    >>> wt=pysal.threshold_binaryW_from_shapefile("examples/columbus.shp",thresh)
    >>> wt.min_neighbors
    1
    >>> wt.histogram
    [(1, 4), (2, 8), (3, 6), (4, 2), (5, 5), (6, 8), (7, 6), (8, 2), (9, 6), (10, 1), (11, 1)]
    >>> wt.neighbors[0]
    [1, 2]
    >>> wt.neighbors[1]
    [3, 0]

Distance band weights can also be specified to take on continuous values rather
than binary, with the values set to the inverse distance separating each pair
within a given threshold distance. We illustrate this with a small set of 6
points:

    >>> points=[(10, 10), (20, 10), (40, 10), (15, 20), (30, 20), (30, 30)]
    >>> wid=pysal.threshold_continuousW_from_array(points,11.2)
    >>> wid.weights[0]
    [0.10000000000000001, 0.089442719099991588]

If we change the distance decay exponent to -2.0 the result is so called gravity weights;

    >>> wid2=pysal.threshold_continuousW_from_array(points,11.2,alpha=-2.0)
    >>> wid2.weights[0]
    [0.01, 0.0079999999999999984]


Kernel Weights
--------------

A combination of distance based thresholds together with  continuously valued
weights is supported through kernel weights:

    >>> points=[(10, 10), (20, 10), (40, 10), (15, 20), (30, 20), (30, 30)]
    >>> kw=pysal.Kernel(points)
    >>> kw.weights[0]
    [1.0, 0.50000004999999503, 0.44098306152674649]
    >>> kw.neighbors[0]
    [0, 1, 3]
    >>> kw.bandwidth
    array([[ 20.000002],
           [ 20.000002],
           [ 20.000002],
           [ 20.000002],
           [ 20.000002],
           [ 20.000002]])


The bandwith attribute plays the role of the distance threshold with kernel
weights, while the form of the kernel function determines the distance decay in
the derived continuous weights. In the above example, the bandwidth is set to
the default value and fixed across the observations. The user could specify
a different value for a fixed bandwidth:

    >>> kw15=pysal.Kernel(points,bandwidth=15.0)
    >>> kw15[0]
    {0: 1.0, 1: 0.33333333333333337, 3: 0.2546440075000701}
    >>> kw15.neighbors[0]
    [0, 1, 3]
    >>> kw15.bandwidth
    array([[ 15.],
           [ 15.],
           [ 15.],
           [ 15.],
           [ 15.],
           [ 15.]])

which results in fewer neighbors for the first unit.  Adaptive bandwidths (i.e., different bandwiths
for each unit) can also be user specified:

    >>> bw=[25.0,15.0,25.0,16.0,14.5,25.0]
    >>> kwa=pysal.Kernel(points,bandwidth=bw)
    >>> kwa.weights[0]
    [1.0, 0.59999999999999998, 0.55278640450004202, 0.10557280900008403]
    >>> kwa.neighbors[0]
    [0, 1, 3, 4]
    >>> kwa.bandwidth
    array([[ 25. ],
           [ 15. ],
           [ 25. ],
           [ 16. ],
           [ 14.5],
           [ 25. ]])

Alternatively the adaptive bandwidths could be defined endogenously:

    >>> kwea=pysal.Kernel(points,fixed=False)
    >>> kwea.weights[0]
    [1.0, 0.10557289844279438, 9.9999990066379496e-08]
    >>> kwea.neighbors[0]
    [0, 1, 3]
    >>> kwea.bandwidth
    array([[ 11.18034101],
           [ 11.18034101],
           [ 20.000002  ],
           [ 11.18034101],
           [ 14.14213704],
           [ 18.02775818]])

Finally, the kernel function could be changed (with endogenous adaptive bandwidths):

    >>> kweag=pysal.Kernel(points,fixed=False,function='gaussian')
    >>> kweag.weights[0]
    [0.3989422804014327, 0.26741902915776961, 0.24197074871621341]
    >>> kweag.bandwidth
    array([[ 11.18034101],
           [ 11.18034101],
           [ 20.000002  ],
           [ 11.18034101],
           [ 14.14213704],
           [ 18.02775818]])


More details on kernel weights can be found in 
:class:`~pysal.weights.Distance.Kernel`. 


A Closer look at W
==================

Although the three different types of spatial weights illustrated above cover a wide array of approaches
towards specifying spatial relations, they all share common attributes from the base W class in PySAL. Here 
we take a closer look at some of the more useful properties of this class.

Weight Transformations
----------------------

Often there is a need to apply a transformation to the spatial weights, such as in the case of row standardization.
Here each value in the row of the spatial weights matrix is rescaled to sum to one:

.. math::
   
     ws_{i,j} = w_{i,j}/ \sum_j w_{i,j}

This and other weights transformations in PySAL are supported by the transform property of the W class. To see this 
let's build a simple contiguity object for the Columbus data set:

    >>> w=pysal.rook_from_shapefile("examples/columbus.shp")
    >>> w.weights[0]
    [1.0, 1.0]

We can row standardize this by setting the transform property:

    >>> w.transform='r'
    >>> w.weights[0]
    [0.5, 0.5]

If the original weights (unstandardized) are required, the transform property can be reset:

    >>> w.transform='o'
    >>> w.weights[0]
    [1.0, 1.0]
 
Behind the scenes the transform property is updating all other characteristics of the spatial weights that are a function of the
values and these standardization operations, freeing the user from having to keep these other attributes updated. To determine the current
value of the transformation, simply query this attrbute:

    >>> w.transform
    'O'

More details on other transformations that are supported in W can be found in
:class:`pysal.weights.W`. 


W related functions
===================

Generating a full array
-----------------------
As the underlying data structure of the weights in W is based on a sparse representation, there may be a need to work with the full numpy array.
This is supported through the full method of W:

    >>> wf=w.full()
    >>> len(wf)
    2

The first element of the return from w.full is the numpy array:
    
    >>> wf[0].shape
    (49, 49)

while the second element contains the ids for the row (column) ordering of the array:

    >>> wf[1][0:5]
    >>> wf[1][0:5]
    [0, 1, 2, 3, 4]

If only the array is required, a simple Python slice can be used:

    >>> wf = w.full()[0]
    

Shimbel Matrices
----------------
The Shimbel matrix for a set of n objects contains the shortest path distance separating each pair of units.
This has wide use in spatial analysis for solving different types of clustering and optimization problems. Calling the shimbel
method of a W object generates this information:

    >>> w=pysal.lat2W(3,3)
    >>> ws=w.shimbel()
    >>> ws[0]
    [-1, 1, 2, 1, 2, 3, 2, 3, 4]

Thus we see that observation 0 (the north east cell of our 3x3 lattice) is a first order neighbor to observations 1 and 3, second order
neighbor to observations 2, 4, and 6, a third order neighbor to 5, and 7, and a fourth order neighbor to observation 8 (the extreme south east 
cell in the lattice). The position of the -1 simply denotes the focal unit.

Higher Order Contiguity Weights
-------------------------------

Closely related to the shortest path distances is the concept of a spatial weight based on a particular order of contiguity. For example, we could
define the second order contiguity relations using:

    >>> w2=w.higher_order(2)
    >>> w2.neighbors[0]
    [2, 4, 6]

or a fourth order set of weights:

    >>> w4=w.higher_order(4)
    >>> w4.neighbors[0]
    [8]

In both cases a new instance of the W object is returned with the weights and neighbors defined using the particular order of contiguity.

Spatial Lag
-----------

The final function related to spatial weights that we illustrate here is used to construct a new variable called the spatial lag. The spatial
lag is a function of the attribute values observed at neighboring locations. For example, if we continue with our regular 3x3 lattice and
create an attribute variable y:

    >>> import numpy as np
    >>> y=np.arange(w.n)
    >>> y
    array([0, 1, 2, 3, 4, 5, 6, 7, 8])

then the spatial lag can be constructed with:
    
    >>> yl=pysal.lag_spatial(w,y)
    >>> yl
    array([  4.,   6.,   6.,  10.,  16.,  14.,  10.,  18.,  12.])

Mathematically, the spatial lag is a weighted sum of neighboring attribute values

.. math::
    
    yl_i = \sum_j w_{i,j} y_j

In the example above, the weights were binary, based on the rook criterion. If we row standardize our W object first
and then recalculate the lag, it takes the form of a weighted average of the neighboring attribute values:

    >>> w.transform='r'
    >>> ylr=pysal.lag_spatial(w,y)
    >>> ylr
    array([ 2.        ,  2.        ,  3.        ,  3.33333333,  4.        ,
            4.66666667,  5.        ,  6.        ,  6.        ])


One important consideration in calculating the spatial lag is that the ordering
of the values in y aligns with the underling order in W.  In cases where the
source for your attribute data is different from the one to construct your
weights you may need to reorder your y values accordingly.  To check if this is
the case you can find the order in W as follows:

    >>> w.id_order
    [0, 1, 2, 3, 4, 5, 6, 7, 8]

In this case the lag_spatial function assumes that the first value in the y
attribute corresponds to unit 0 in the lattice (northwest cell), while the last
value in y would correspond to unit 8 (southeast cell). In other words, for the
value of the spatial lag to be valid the number of elements in y must match w.n
and the orderings must be aligned. 

Fortunately, for the common use case where both the attribute and weights information come from a
shapefile (and its dbf), PySAL handles the alignment automatically: [#]_

    >>> w=pysal.rook_from_shapefile("examples/columbus.shp")
    >>> f=pysal.open("examples/columbus.dbf")
    >>> f.header
    ['AREA', 'PERIMETER', 'COLUMBUS_', 'COLUMBUS_I', 'POLYID', 'NEIG', 'HOVAL', 'INC', 'CRIME', 'OPEN', 'PLUMB', 'DISCBD', 'X', 'Y', 'NSA', 'NSB', 'EW', 'CP', 'THOUS', 'NEIGNO']
    >>> y=np.array(f.by_col['INC'])
    >>> w.transform='r'
   >>> y
    array([ 19.531   ,  21.232   ,  15.956   ,   4.477   ,  11.252   ,
            16.028999,   8.438   ,  11.337   ,  17.586   ,  13.598   ,
             7.467   ,  10.048   ,   9.549   ,   9.963   ,   9.873   ,
             7.625   ,   9.798   ,  13.185   ,  11.618   ,  31.07    ,
            10.655   ,  11.709   ,  21.155001,  14.236   ,   8.461   ,
             8.085   ,  10.822   ,   7.856   ,   8.681   ,  13.906   ,
            16.940001,  18.941999,   9.918   ,  14.948   ,  12.814   ,
            18.739   ,  17.017   ,  11.107   ,  18.476999,  29.833   ,
            22.207001,  25.872999,  13.38    ,  16.961   ,  14.135   ,
            18.323999,  18.950001,  11.813   ,  18.796   ])
    >>> yl=pysal.lag_spatial(w,y)
    >>> yl
    array([ 18.594     ,  13.32133333,  14.123     ,  14.94425   ,
            11.817857  ,  14.419     ,  10.283     ,   8.3364    ,
            11.7576665 ,  19.48466667,  10.0655    ,   9.1882    ,
             9.483     ,  10.07716667,  11.231     ,  10.46185714,
            21.94100033,  10.8605    ,  12.46133333,  15.39877778,
            14.36333333,  15.0838    ,  19.93666633,  10.90833333,
             9.7       ,  11.403     ,  15.13825   ,  10.448     ,
            11.81      ,  12.64725   ,  16.8435    ,  26.0662505 ,
            15.6405    ,  18.05175   ,  15.3824    ,  18.9123996 ,
            12.2418    ,  12.76675   ,  18.5314995 ,  22.79225025,
            22.575     ,  16.8435    ,  14.2066    ,  14.20075   ,
            15.2515    ,  18.6079995 ,  26.0200005 ,  15.818     ,  14.303     ])
    
    >>> w.id_order
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]






.. 
.. WSets
.. =====
.. 
.. add discussion of WSets here




.. rubric:: Footnotes

.. [#] Although this tutorial provides an introduction to the functionality of the PySAL weights class, it is not exhaustive. Complete documentation for the class and associated functions can be found by accessing the help from within a Python interpreter. 
.. [#] The dictionaries for the weights and value attributes in W are read-only in.
.. [#] Ties at the k-nn distance band are randomly broken to ensure each observation has exactly k neighbors.
.. [#] The ordering exploits the one-to-one relation between a record in the DBF file and the shape in the shapefile.
	
	
