.. testsetup:: * 

        import pysal
        import numpy as np

#######################
Spatial Autocorrelation
#######################

.. contents::

Introduction
============

Spatial autocorrelation pertains to the non-random pattern of attribute values
over a set of spatial units. This can take two general forms: positive
autocorrelation which reflects value similarity in space, and negative
autocorrelation or value dissimilarity in space. In either case the
autocorrelation arises when the observed spatial pattern is different from what would
be expected under a random process operating in space.

Spatial autocorrelation can be analyzed from two different perspectives. Global
autocorrelation analysis involves the study of the entire map pattern and
generally asks the question as to whether the pattern displays clustering or
not. Local autocorrelation, on the other hand, shifts the focus to explore
within the global pattern to identify clusters or so called hot spots that may be
either driving the overall clustering pattern, or that reflect heterogeneities
that depart from global pattern.

In what follows, we first highlight the global spatial autocorrelation classes
in PySAL. This is followed by an illustration of the analysis of local spatial
autocorrelation.

Global Autocorrelation
======================

PySAL implements three different tests for global spatial autocorrelation:
Moran's I, Geary's C, and Getis and Ord's G.

Moran's I
---------

Moran's I measures the global spatial autocorrelation in an attribute :math:`y` measured over :math:`n` spatial units and is given as:

.. math::

        I = n/S_0  \sum_{i}\sum_j z_i w_{i,j} z_j / \sum_i z_i z_i

where :math:`w_{i,j}` is a spatial :doc:`weight <weights>`, :math:`z_i = y_i - \bar{y}`, and :math:`S_0=\sum_i\sum_j w_{i,j}`.  We illustrate the use of Moran's I with a case study of homicide rates for a group of 78 counties surrounding St. Louis over the period 1988-93. [#]_
We start with the usual imports:


.. doctest:: 

        import pysal
        import numpy as np
        np.random.seed(10)

Next, we read in the homicide rates:

.. doctest::

        >>> f = pysal.open("../pysal/examples/stl_hom.txt")
        >>> y = np.array(f.by_col['HR8893'])

To calculate Moran's I we first need to read in a GAL file for a rook weights
matrix and create an instance of W:

.. doctest::

        >>> w = pysal.open("../pysal/examples/stl.gal").read()
        
The instance of Moran's I can then be obtained with:

.. doctest::

        >>> mi = pysal.Moran(y, w)
        >>> mi.I
        0.24365582621771659
        >>> mi.EI
        -0.012987012987012988
        >>> mi.p_norm
        0.00027147862770937614

From these results, we see that the observed value for I is significantly above its expected value, under the assumption of normality for the homicide rates. 

If we peek inside the mi object to learn more:

        >>> help(mi)

which generates::

        Help on instance of Moran in module pysal.esda.moran:

        class Moran
         |  Moran's I Global Autocorrelation Statistic
         |  
         |  Parameters
         |  ----------
         |  
         |  y               : array
         |                    variable measured across n spatial units
         |  w               : W
         |                    spatial weights instance
         |  permutations    : int
         |                    number of random permutations for calculation of pseudo-p_values
         |  
         |  
         |  Attributes
         |  ----------
         |  y            : array
         |                 original variable
         |  w            : W
         |                 original w object
         |  permutations : int
         |                 number of permutations
         |  I            : float
         |                 value of Moran's I
         |  EI           : float
         |                 expected value under normality assumption
         |  VI_norm      : float
         |                 variance of I under normality assumption
         |  seI_norm     : float
         |                 standard deviation of I under normality assumption
         |  z_norm       : float
         |                 z-value of I under normality assumption
         |  p_norm       : float
         |                 p-value of I under normality assumption (one-sided)
         |                 for two-sided tests, this value should be multiplied by 2
         |  VI_rand      : float
         |                 variance of I under randomization assumption
         |  seI_rand     : float
         |                 standard deviation of I under randomization assumption
         |  z_rand       : float
         |                 z-value of I under randomization assumption
         |  p_rand       : float
         |                 p-value of I under randomization assumption (1-tailed)
         |  sim          : array (if permutations>0)
        
we see that we can base the inference not only on the normality assumption, but also on random permutations of the values on the spatial units to generate a reference distribution for I under the null:

.. doctest::

        >>> mir = pysal.Moran(y, w, permutations = 9999)

The pseudo p value based on these permutations is: 

.. doctest::

        >>> print mir.p_sim
        0.0015

in other words there were 14 permutations that generated values for I that
were as extreme as the original value, so the p value becomes (14+1)/(9999+1). [#]_
Alternatively, we could use the realized values for I from the permutations and
compare the original I using a z-transformation to get:

.. doctest::

        >>> print mir.EI_sim
        -0.0136555651205
        >>> print mir.z_sim
        4.74311431149
        >>> print mir.p_z_sim
        2.10457431304e-06

When the variable of interest (:math:`y`) is rates based on populations with different sizes, 
the Moran's I value for :math:`y` needs to be adjusted to account for the differences among populations. [#]_
To apply this adjustment, we can create an instance of the Moran_Rate class rather than the Moran class.
For example, let's assume that we want to estimate the Moran's I for the rates of newborn infants who died of 
Sudden Infant Death Syndrome (SIDS). We start this estimation by reading in the total number of newborn infants (BIR79)
and the total number of newborn infants who died of SIDS (SID79):

.. doctest::

        >>> f = pysal.open(pysal.examples.get_path("sids2.dbf"))
        >>> b = np.array(f.by_col('BIR79'))
        >>> e = np.array(f.by_col('SID79'))

Next, we create an instance of W:

.. doctest::

        >>> w = pysal.open(pysal.examples.get_path("sids2.gal")).read()

Now, we create an instance of Moran_Rate:

.. doctest::

        >>> mi = pysal.esda.moran.Moran_Rate(e, b, w)
        >>> "%6.4f" % mi.I
        '0.1662'
        >>> "%6.4f" % mi.EI
        '-0.0101'
        >>> "%6.4f" % mi.p_norm
        '0.0084'

From these results, we see that the observed value for I is significantly higher than its expected value,
after the adjustment for the differences in population.


Geary's C
---------
The second statistic for global spatial autcorrelation implemented in PySAL is Geary's C:

.. math::

        C=\frac{(n-1)}{2S_0} \sum_i\sum_j w_{i,j} (y_i-y_j)^2 / \sum_i z_i^2

with all the terms defined as above. Applying this to the St. Louis data:

.. doctest::

        >>> gc = pysal.Geary(y, w)
        >>> print gc.C
        0.586776506108
        >>> gc.EC
        1.0
        >>> print gc.z_norm
        -4.99194306621
        >>> gc.p_norm
        2.9887438468545469e-07

we see that the statistic :math:`C` is significantly lower than its expected
value :math:`EC`. Although the sign of the standardized statistic is negative (in contrast to what held for :math:`I`, the interpretation is the same, namely evidence of strong positive spatial autocorrelation in the homicide rates.

Similar to what we saw for Moran's I, we can base inference on Geary's C using random spatial permutations:

.. doctest::

        >>> gc = pysal.Geary(y, w, permutations = 9999)
        >>> print gc.p_z_sim
        0.0210556086187
        >>> print gc.p_sim
        0.0051

with the first p-value based on a z-transform of the observed C relative to the
distribution of values obtained in the permutations, and the second based on
the cumulative probability of the observed value in the empirical distribution.

Getis and Ord's G
-----------------
The last statistic for global spatial autcorrelation implemented in PySAL is Getis and Ord's G:

.. math::

        G(d)=\frac{\sum_i\sum_j w_{i,j}(d) y_i y_j}{\sum_i\sum_j y_i y_j}

where :math:`d` is a threshold distance used to define a spatial :doc:`weight <weights>`.
Only :class:`pysal.weights.Distance.DistanceBand` weights objects are applicable to Getis and Ord's G.
Applying this to the St. Louis data:

.. doctest::

        >>> dist_w = pysal.threshold_binaryW_from_shapefile('../pysal/examples/stl_hom.shp',0.6)
        >>> dist_w.transform = "B"
        >>> from pysal.esda.getisord import G
        >>> g = G(y, dist_w)
        >>> print g.G
        0.103483215873
        >>> print g.EG
        0.0752580752581
        >>> print g.z_norm
        3.28090342959
        >>> print g.p_norm
        0.000517375830488

Although we switched the contiguity-based weights object into another distance-based one,
we see that the statistic :math:`G` is significantly higher than its expected
value :math:`EG` under the assumption of normality for the homicide rates.

Similar to what we saw for Moran's I and Geary's C, we can base inference on Getis and Ord's G using random spatial permutations:

.. doctest::

        >>> g = G(y, dist_w, permutations = 9999)
        >>> print g.p_z_sim
        0.00061476957041
        >>> print g.p_sim
        0.0061

with the first p-value based on a z-transform of the observed G relative to the
distribution of values obtained in the permutations, and the second based on
the cumulative probability of the observed value in the empirical distribution.

Local Autocorrelation
=====================

.. _lisa:

To measure local autocorrelation quantitatively, 
PySAL implements Local Indicators of Spatial Association (LISAs) for Moran's I and Getis and Ord's G.

Local Moran's I
----------------

PySAL implements local Moran's I as follows:

.. math::

        I_i =  \sum_j z_i w_{i,j} z_j / \sum_i z_i z_i

which results in :math:`n` values of local spatial autocorrelation, 1 for each spatial unit. Continuing on with the St. Louis example, the LISA statistics are obtained with:

.. doctest::

        >>> lm = pysal.Moran_Local(y, w)
        >>> lm.n
        78
        >>> len(lm.Is)
        78
        
thus we see 78 LISAs are stored in the vector lm.Is. Inference about these values is obtained through conditional randomization [#]_ which leads to pseudo p-values for each LISA:

.. doctest::

        >>> lm.p_sim
        array([ 0.201,  0.077,  0.398,  0.29 ,  0.363,  0.06 ,  0.302,  0.225,
                0.043,  0.06 ,  0.249,  0.489,  0.457,  0.39 ,  0.431,  0.445,
                0.481,  0.423,  0.405,  0.192,  0.147,  0.03 ,  0.366,  0.437,
                0.281,  0.343,  0.227,  0.325,  0.347,  0.392,  0.495,  0.435,
                0.004,  0.424,  0.261,  0.012,  0.003,  0.001,  0.062,  0.002,
                0.096,  0.421,  0.452,  0.305,  0.266,  0.012,  0.032,  0.037,
                0.051,  0.13 ,  0.306,  0.32 ,  0.11 ,  0.481,  0.036,  0.283,
                0.112,  0.336,  0.322,  0.368,  0.307,  0.424,  0.363,  0.482,
                0.361,  0.259,  0.25 ,  0.416,  0.185,  0.177,  0.258,  0.401,
                0.44 ,  0.152,  0.37 ,  0.435,  0.085,  0.121])
        >>>

To identify the significant [#]_ LISA values we can use numpy indexing:

.. doctest::

        >>> sig = lm.p_sim<0.05
        >>> lm.p_sim[sig]
        array([ 0.043,  0.03 ,  0.004,  0.012,  0.003,  0.001,  0.002,  0.012,
                0.032,  0.037,  0.036])

and then use this indexing on the q attribute to find out which quadrant of the Moran scatter plot each of the significant values is contained in:

.. doctest::

        >>> lm.q[sig]
        array([4, 4, 1, 3, 1, 3, 1, 1, 3, 3, 3])

As in the case of global Moran's I, when the variable of interest is rates based on populations with different sizes,
we need to account for the differences among population to estimate local Moran's Is. 
Continuing on with the SIDS example above, the adjusted local Moran's Is are obtained with:

.. doctest::

        >>> lm = pysal.esda.moran.Moran_Local_Rate(e, b, w)
        >>> lm.Is[:10]
        array([-0.13452366, -1.21133985,  0.05019761,  0.06127125, -0.12627466,
                0.23497679,  0.26345855, -0.00951288, -0.01517879, -0.34513514])

As demonstrated above, significant Moran's Is can be idenfied by using numpy indexing:

.. doctest::

        >>> sig = lm.p_sim<0.05
        >>> lm.p_sim[sig]
        array([ 0.022,  0.036,  0.047,  0.021,  0.001,  0.028,  0.029,  0.023,
                0.027,  0.017,  0.006,  0.001])

Local G and G*
--------------

Getis and Ord's G can be localized in two forms: :math:`G_i` and :math:`G^*_i`.

.. math::

        G_i(d) = \frac{\sum_j w_{i,j}(d) y_j - W_i\bar{y}(i)}{s(i)\{[(n-1)S_{1i} - W^2_i]/(n-2)\}^(1/2)}, j \neq i

.. math::

        G^*_i(d) = \frac{\sum_j w_{i,j}(d) y_j - W^*_i\bar{y}}{s\{[(nS^*_{1i}) - (W^*_i)^2]/(n-1)\}^(1/2)}, j = i

where we have :math:`W_i = \sum_{j \neq i} w_{i,j}(d)`, :math:`\bar{y}(i) = \frac{\sum_j y_j}{(n-1)}`, :math:`s^2(i) = \frac{\sum_j y^2_j}{(n-1)} - [\bar{y}(i)]^2`, :math:`W^*_i = W_i + w{i,i}`, :math:`S_{1i} = \sum_j w^2_{i,j} (j \neq i)`, and :math:`S^*_{1i} = \sum_j w^2_{i,j} (\forall j)`, :math:`\bar{y}` and :math:`s^2` denote the usual sample mean and variance of :math:`y`.

Continuing on with the St. Louis example, the :math:`G_i` and :math:`G^*_i` statistics are obtained with:

.. doctest::

        >>> from pysal.esda.getisord import G_Local
        >>> lg = G_Local(y, dist_w)
        >>> lg.n
        78
        >>> len(lg.Gs)
        78
        >>> lgstar = G_Local(y, dist_w, star=True)
        >>> lgstar.n
        78
        >>> len(lgstar.Gs)
        78
        
thus we see 78 :math:`G_i` and :math:`G^*_i` are stored in the vector lg.Gs and lgstar.Gs, respectively. Inference about these values is obtained through conditional randomization as in the case of local Moran's I:

.. doctest::

        >>> lg.p_sim
        array([ 0.339,  0.051,  0.478,  0.016,  0.069,  0.005,  0.08 ,  0.169,
                0.076,  0.079,  0.409,  0.297,  0.148,  0.418,  0.329,  0.498,
                0.458,  0.287,  0.416,  0.183,  0.163,  0.001,  0.321,  0.05 ,
                0.304,  0.337,  0.224,  0.102,  0.257,  0.48 ,  0.471,  0.476,
                0.003,  0.437,  0.034,  0.101,  0.002,  0.24 ,  0.236,  0.025,
                0.101,  0.302,  0.407,  0.263,  0.278,  0.019,  0.032,  0.011,
                0.001,  0.113,  0.028,  0.209,  0.047,  0.333,  0.04 ,  0.108,
                0.102,  0.399,  0.24 ,  0.358,  0.362,  0.402,  0.478,  0.455,
                0.354,  0.266,  0.268,  0.476,  0.136,  0.168,  0.203,  0.404,
                0.489,  0.144,  0.265,  0.382,  0.092,  0.129])
        >>>

To identify the significant :math:`G_i' values we can use numpy indexing:

.. doctest::

        >>> sig = lg.p_sim<0.05
        >>> lg.p_sim[sig]
        array([ 0.016,  0.005,  0.001,  0.003,  0.034,  0.002,  0.025,  0.019,
                0.032,  0.011,  0.001,  0.028,  0.047,  0.04 ])

.. rubric:: Footnotes

.. [#] Source: S. Messner, L. Anselin, D. Hawkins, G. Deane, S. Tolnay, R. Baller (2000). An Atlas of the Spatial Patterning of County-Level Homicide, 1960-1990. Pittsburgh, PA, National Consortium on Violence Research (NCOVR)
.. [#] Because the permutations are random, results from those presented here may vary if you replicate this example.
.. [#] Source: Assuncao, R. E. and Reis, E. A. 1999. A new proposal to adjust Moran's I for population density. Statistics in Medicine. 18, 2147-2162.
.. [#] The n-1 spatial units other than i are used to generate the empirical distribution of the LISA statistics for each i.
.. [#] Caution is required in interpreting the significance of the LISA statistics due to difficulties with multiple comparisons and a lack of independence across the individual tests. For further discussion see Anselin, L. (1995). "Local indicators of spatial association – LISA". Geographical Analysis, 27, 93-115.

